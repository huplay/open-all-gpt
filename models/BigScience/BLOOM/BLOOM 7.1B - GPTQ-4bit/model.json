{
  "name": "BLOOM 7.1B - GPTQ-4bit quantized",
  "transformerType": "BIG_SCIENCE_BLOOM",
  "repo": "https://huggingface.co/iproskurina/bloom-7b1-gptq-4bit",
  "files": ["config.json", "model.safetensors", "quantize_config.json"],
  "parameterNaming": "transformer.{name}",
  "decoderParameterNaming": "transformer.h.{decoderId}.{name}",
  "memorySize": 12288,
  "quantization":
  {
    "quantizationType": "GPTQ"
  }
}
