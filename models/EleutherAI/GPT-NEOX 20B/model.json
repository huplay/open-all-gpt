{
  "name": "EleutherAI GPT-NeoX 20B",
  "transformerType": "ELEUTHERAI_GPT_NEOX",
  "repo": "https://huggingface.co/EleutherAI/gpt-neox-20b",
  "files": [
    "config.json",
    "model-00001-of-00046.safetensors",
    "model-00002-of-00046.safetensors",
    "model-00003-of-00046.safetensors",
    "model-00004-of-00046.safetensors",
    "model-00005-of-00046.safetensors",
    "model-00006-of-00046.safetensors",
    "model-00007-of-00046.safetensors",
    "model-00008-of-00046.safetensors",
    "model-00009-of-00046.safetensors",
    "model-00010-of-00046.safetensors",
    "model-00011-of-00046.safetensors",
    "model-00012-of-00046.safetensors",
    "model-00013-of-00046.safetensors",
    "model-00014-of-00046.safetensors",
    "model-00015-of-00046.safetensors",
    "model-00016-of-00046.safetensors",
    "model-00017-of-00046.safetensors",
    "model-00018-of-00046.safetensors",
    "model-00019-of-00046.safetensors",
    "model-00020-of-00046.safetensors",
    "model-00021-of-00046.safetensors",
    "model-00022-of-00046.safetensors",
    "model-00023-of-00046.safetensors",
    "model-00024-of-00046.safetensors",
    "model-00025-of-00046.safetensors",
    "model-00026-of-00046.safetensors",
    "model-00027-of-00046.safetensors",
    "model-00028-of-00046.safetensors",
    "model-00029-of-00046.safetensors",
    "model-00030-of-00046.safetensors",
    "model-00031-of-00046.safetensors",
    "model-00032-of-00046.safetensors",
    "model-00033-of-00046.safetensors",
    "model-00034-of-00046.safetensors",
    "model-00035-of-00046.safetensors",
    "model-00036-of-00046.safetensors",
    "model-00037-of-00046.safetensors",
    "model-00038-of-00046.safetensors",
    "model-00039-of-00046.safetensors",
    "model-00040-of-00046.safetensors",
    "model-00041-of-00046.safetensors",
    "model-00042-of-00046.safetensors",
    "model-00043-of-00046.safetensors",
    "model-00044-of-00046.safetensors",
    "model-00045-of-00046.safetensors",
    "model-00046-of-00046.safetensors"
  ],
  "decoderParameterNaming": "gpt_neox.layers.{decoderId}.{name}",
  "memorySize": 32528,
  "quantize": {
    "quantizationType": "QLoRA",
    "outputFloatType": "FLOAT_16",
    "config": {
      "variant": "fp4",
      "blockSize": 128
    }
  }
}
