{
  "name": "Meta Llama 7B",
  "transformerType": "META_LLAMA",
  "repo": "https://huggingface.co/huggyllama/llama-30b",
  "files": [
    "config.json",
    "model-00001-of-00007.safetensors",
    "model-00002-of-00007.safetensors",
    "model-00003-of-00007.safetensors",
    "model-00004-of-00007.safetensors",
    "model-00005-of-00007.safetensors",
    "model-00006-of-00007.safetensors",
    "model-00007-of-00007.safetensors"
  ],
  "parameterNaming": "model.{name}",
  "decoderParameterNaming": "model.layers.{decoderId}.{name}",
  "memorySize": 11264
}
