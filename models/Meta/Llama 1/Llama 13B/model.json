{
  "name": "Meta Llama 7B",
  "transformerType": "META_LLAMA",
  "repo": "https://huggingface.co/huggyllama/llama-13b",
  "files": [
    "config.json",
    "model-00001-of-00003.safetensors",
    "model-00002-of-00003.safetensors",
    "model-00003-of-00003.safetensors"
  ],
  "parameterNaming": "model.{name}",
  "decoderParameterNaming": "model.layers.{decoderId}.{name}",
  "memorySize": 11264
}
