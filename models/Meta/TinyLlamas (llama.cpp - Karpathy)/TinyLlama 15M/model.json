{
  "name": "Karpathy tinyLlama 15M",
  "transformerType": "META_LLAMA",
  "--original repo--": "https://huggingface.co/karpathy/tinyllamas",
  "repo": "https://huggingface.co/nickypro/tinyllama-15M",
  "files": ["config.json", "model.safetensors"],
  "parameterNaming": "model.{name}",
  "decoderParameterNaming": "model.layers.{decoderId}.{name}",
  "memorySize": 1024,
  "quantize": {
    "quantizationType": "LLM_INT_8",
    "outputFloatType": "FLOAT_16",
    "config": {
      "threshold": 6.0
    }
  }
}
